{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scott/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/scott/anaconda3/lib/python3.6/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import sklearn.learning_curve as curves\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cross_validation import ShuffleSplit, train_test_split\n",
    "\n",
    "def ModelLearning(X, y):\n",
    "    \"\"\" Calculates the performance of several models with varying sizes of training data.\n",
    "        The learning and testing scores for each model are then plotted. \"\"\"\n",
    "    \n",
    "    # Create 10 cross-validation sets for training and testing\n",
    "    cv = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.2, random_state = 0)\n",
    "\n",
    "    # Generate the training set sizes increasing by 50\n",
    "    train_sizes = np.rint(np.linspace(1, X.shape[0]*0.8 - 1, 9)).astype(int)\n",
    "\n",
    "    # Create the figure window\n",
    "    fig = plt.figure(figsize=(10,7))\n",
    "\n",
    "    # Create three different models based on max_depth\n",
    "    for k, depth in enumerate([1,3,6,10]):\n",
    "        \n",
    "        # Create a Decision tree regressor at max_depth = depth\n",
    "        regressor = DecisionTreeRegressor(max_depth = depth)\n",
    "\n",
    "        # Calculate the training and testing scores\n",
    "        sizes, train_scores, test_scores = curves.learning_curve(regressor, X, y, \\\n",
    "            cv = cv, train_sizes = train_sizes, scoring = 'r2')\n",
    "        \n",
    "        # Find the mean and standard deviation for smoothing\n",
    "        train_std = np.std(train_scores, axis = 1)\n",
    "        train_mean = np.mean(train_scores, axis = 1)\n",
    "        test_std = np.std(test_scores, axis = 1)\n",
    "        test_mean = np.mean(test_scores, axis = 1)\n",
    "\n",
    "        # Subplot the learning curve \n",
    "        ax = fig.add_subplot(2, 2, k+1)\n",
    "        ax.plot(sizes, train_mean, 'o-', color = 'r', label = 'Training Score')\n",
    "        ax.plot(sizes, test_mean, 'o-', color = 'g', label = 'Testing Score')\n",
    "        ax.fill_between(sizes, train_mean - train_std, \\\n",
    "            train_mean + train_std, alpha = 0.15, color = 'r')\n",
    "        ax.fill_between(sizes, test_mean - test_std, \\\n",
    "            test_mean + test_std, alpha = 0.15, color = 'g')\n",
    "        \n",
    "        # Labels\n",
    "        ax.set_title('max_depth = %s'%(depth))\n",
    "        ax.set_xlabel('Number of Training Points')\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.set_xlim([0, X.shape[0]*0.8])\n",
    "        ax.set_ylim([-0.05, 1.05])\n",
    "    \n",
    "    # Visual aesthetics\n",
    "    ax.legend(bbox_to_anchor=(1.05, 2.05), loc='lower left', borderaxespad = 0.)\n",
    "    fig.suptitle('Decision Tree Regressor Learning Performances', fontsize = 16, y = 1.03)\n",
    "    fig.tight_layout()\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def ModelComplexity(X, y):\n",
    "    \"\"\" Calculates the performance of the model as model complexity increases.\n",
    "        The learning and testing errors rates are then plotted. \"\"\"\n",
    "    \n",
    "    # Create 10 cross-validation sets for training and testing\n",
    "    cv = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.2, random_state = 0)\n",
    "\n",
    "    # Vary the max_depth parameter from 1 to 10\n",
    "    max_depth = np.arange(1,11)\n",
    "\n",
    "    # Calculate the training and testing scores\n",
    "    train_scores, test_scores = curves.validation_curve(DecisionTreeRegressor(), X, y, \\\n",
    "        param_name = \"max_depth\", param_range = max_depth, cv = cv, scoring = 'r2')\n",
    "\n",
    "    # Find the mean and standard deviation for smoothing\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "    test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    # Plot the validation curve\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.title('Decision Tree Regressor Complexity Performance')\n",
    "    plt.plot(max_depth, train_mean, 'o-', color = 'r', label = 'Training Score')\n",
    "    plt.plot(max_depth, test_mean, 'o-', color = 'g', label = 'Validation Score')\n",
    "    plt.fill_between(max_depth, train_mean - train_std, train_mean + train_std, alpha = 0.15, color = 'r')\n",
    "    plt.fill_between(max_depth, test_mean - test_std, test_mean + test_std, alpha = 0.15, color = 'g')\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.xlabel('Maximum Depth')\n",
    "    plt.ylabel('Score')\n",
    "    plt.ylim([-0.05,1.05])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def PredictTrials(X, y, fitter, data):\n",
    "    \"\"\" Fit and predict data. \"\"\"\n",
    "\n",
    "    # Store the predicted prices\n",
    "    prices = []\n",
    "\n",
    "    for k in range(10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = k)\n",
    "        reg = fitter(X_train, y_train)\n",
    "        pred = reg.predict([data[0]])[0]\n",
    "        prices.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
